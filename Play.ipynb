{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Maybe you have to !pip3 install torch or !pip install torch\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "seed = 0\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Classes.ipynb for relevant classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Classes.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Players and Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Initialized\n",
      "Memory Initialized\n",
      "Memory Initialized\n",
      "Memory Initialized\n",
      "Memory Initialized\n",
      "Memory Initialized\n",
      "Memory Initialized\n"
     ]
    }
   ],
   "source": [
    "## Initialize Players\n",
    "# 0 for position 'top'\n",
    "# 1 for position 'bottom'\n",
    "\n",
    "# Nr games for training\n",
    "num_iterations = int(2e4) #int(2e5) \n",
    "epsilon_stop = int(num_iterations /2 * 3/5)\n",
    "\n",
    "## AI Agent\n",
    "ai0 = DQNPlayer(gamma=0.97, \n",
    "                learning_rate = 1e-2,\n",
    "                batch_size = 128,\n",
    "                target_net_update_steps = 1000,\n",
    "                replay_memory_capacity = 1e5, \n",
    "                epsilon_start = 1000,\n",
    "                epsilon_stop = epsilon_stop,\n",
    "                epsilon_min = 0.05,\n",
    "                weight_decay = 1e-4,\n",
    "                policy = 'softmax',\n",
    "                pos = 0,\n",
    "                name = 'AI')\n",
    "\n",
    "## AI Agent\n",
    "ai1 = DQNPlayer(gamma=0.97, \n",
    "                learning_rate = 1e-2,\n",
    "                batch_size = 128,\n",
    "                target_net_update_steps = 1000,\n",
    "                replay_memory_capacity = 1e5, \n",
    "                epsilon_start = 1000,\n",
    "                epsilon_stop = epsilon_stop,\n",
    "                epsilon_min = 0.05,\n",
    "                weight_decay = 1e-4,\n",
    "                policy = 'softmax',\n",
    "                pos = 1,\n",
    "                name = 'AI')\n",
    "\n",
    "## Greedy Players (always choose action with max reward)\n",
    "greedy0 = GreedyPlayer(pos=0)\n",
    "greedy1 = GreedyPlayer(pos=1)\n",
    "\n",
    "## Random Players\n",
    "random0 = RandomPlayer(pos=0)\n",
    "random1 = RandomPlayer(pos=1)\n",
    "\n",
    "## Human Player (position: 1-'bottom')\n",
    "human = HumanPlayer(pos=1)\n",
    "\n",
    "## The Game Engine\n",
    "game = Mancala(seed=seed, disp=False)\n",
    "\n",
    "## Everything meets in the 'Arena'\n",
    "arena = Arena(game, ai0, ai1, disp=False) # disp=False to avoid output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every player has its own Memory. \n",
    "\n",
    "This is only relevant for the AIs.\n",
    "\n",
    "The other ones get one for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play one first game human vs greedy\n",
    "\n",
    "The possible actions are 0-11.\n",
    "\n",
    "0 - 5:  choose bowl 0-5, put NO bean into 'Score'\n",
    "\n",
    "6 - 11: choose bowl 0-5 put A bean into 'Score'\n",
    "\n",
    "use 12 to end the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testarena = Arena(game, greedy0, human, disp=True)\n",
    "#testarena.reset()\n",
    "#testarena.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the game, train the AIs\n",
    "\n",
    "Takes a couple of minutes (~10-30min?)\n",
    "\n",
    "Maybe num_iterations = 2e5 is an overkill (if changed, epsilon_stop should be changed as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating target network...\n",
      "Game 1000 / 20000\n",
      "Average Score:  ai0: 24.232    ai1: 23.768\n",
      "Epsilon:        ai0: 0.997     ai1: 1.000\n",
      "Av. Last Loss:  ai0: 3.3111    ai1: 3.2676\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Updating target network...\n",
      "Updating target network...\n",
      "Game 2000 / 20000\n",
      "Average Score:  ai0: 24.040    ai1: 23.960\n",
      "Epsilon:        ai0: 0.895     ai1: 0.915\n",
      "Av. Last Loss:  ai0: 3.0507    ai1: 3.1192\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 3000 / 20000\n",
      "Average Score:  ai0: 24.124    ai1: 23.876\n",
      "Epsilon:        ai0: 0.796     ai1: 0.824\n",
      "Av. Last Loss:  ai0: 3.0155    ai1: 3.0171\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 4000 / 20000\n",
      "Average Score:  ai0: 23.759    ai1: 24.241\n",
      "Epsilon:        ai0: 0.695     ai1: 0.735\n",
      "Av. Last Loss:  ai0: 3.0183    ai1: 3.0702\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 5000 / 20000\n",
      "Average Score:  ai0: 24.304    ai1: 23.696\n",
      "Epsilon:        ai0: 0.599     ai1: 0.641\n",
      "Av. Last Loss:  ai0: 3.0534    ai1: 3.0439\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 6000 / 20000\n",
      "Average Score:  ai0: 23.698    ai1: 24.302\n",
      "Epsilon:        ai0: 0.495     ai1: 0.555\n",
      "Av. Last Loss:  ai0: 3.0456    ai1: 3.0965\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 7000 / 20000\n",
      "Average Score:  ai0: 23.674    ai1: 24.326\n",
      "Epsilon:        ai0: 0.391     ai1: 0.469\n",
      "Av. Last Loss:  ai0: 3.0215    ai1: 3.0772\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 8000 / 20000\n",
      "Average Score:  ai0: 23.910    ai1: 24.090\n",
      "Epsilon:        ai0: 0.289     ai1: 0.381\n",
      "Av. Last Loss:  ai0: 3.0894    ai1: 3.1913\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 9000 / 20000\n",
      "Average Score:  ai0: 23.863    ai1: 24.137\n",
      "Epsilon:        ai0: 0.188     ai1: 0.293\n",
      "Av. Last Loss:  ai0: 3.0525    ai1: 3.1624\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 10000 / 20000\n",
      "Average Score:  ai0: 23.890    ai1: 24.110\n",
      "Epsilon:        ai0: 0.085     ai1: 0.205\n",
      "Av. Last Loss:  ai0: 3.0801    ai1: 3.1494\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 11000 / 20000\n",
      "Average Score:  ai0: 24.287    ai1: 23.713\n",
      "Epsilon:        ai0: 0.050     ai1: 0.114\n",
      "Av. Last Loss:  ai0: 3.1129    ai1: 3.1841\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 12000 / 20000\n",
      "Average Score:  ai0: 24.768    ai1: 23.232\n",
      "Epsilon:        ai0: 0.050     ai1: 0.050\n",
      "Av. Last Loss:  ai0: 3.1094    ai1: 3.1018\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 13000 / 20000\n",
      "Average Score:  ai0: 24.273    ai1: 23.727\n",
      "Epsilon:        ai0: 0.050     ai1: 0.050\n",
      "Av. Last Loss:  ai0: 3.1136    ai1: 3.1748\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 14000 / 20000\n",
      "Average Score:  ai0: 24.343    ai1: 23.657\n",
      "Epsilon:        ai0: 0.050     ai1: 0.050\n",
      "Av. Last Loss:  ai0: 3.1516    ai1: 3.2059\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 15000 / 20000\n",
      "Average Score:  ai0: 23.696    ai1: 24.304\n",
      "Epsilon:        ai0: 0.050     ai1: 0.050\n",
      "Av. Last Loss:  ai0: 3.0822    ai1: 3.2453\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 16000 / 20000\n",
      "Average Score:  ai0: 23.762    ai1: 24.238\n",
      "Epsilon:        ai0: 0.050     ai1: 0.050\n",
      "Av. Last Loss:  ai0: 3.1072    ai1: 3.2724\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 17000 / 20000\n",
      "Average Score:  ai0: 23.900    ai1: 24.100\n",
      "Epsilon:        ai0: 0.050     ai1: 0.050\n",
      "Av. Last Loss:  ai0: 3.0594    ai1: 3.2447\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 18000 / 20000\n",
      "Average Score:  ai0: 23.657    ai1: 24.343\n",
      "Epsilon:        ai0: 0.050     ai1: 0.050\n",
      "Av. Last Loss:  ai0: 3.0539    ai1: 3.2989\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 19000 / 20000\n",
      "Average Score:  ai0: 23.069    ai1: 24.931\n",
      "Epsilon:        ai0: 0.050     ai1: 0.050\n",
      "Av. Last Loss:  ai0: 3.0573    ai1: 3.2933\n",
      "-------------------------------------------\n",
      "Updating target network...\n",
      "Game 20000 / 20000\n",
      "Average Score:  ai0: 23.559    ai1: 24.441\n",
      "Epsilon:        ai0: 0.050     ai1: 0.050\n",
      "Av. Last Loss:  ai0: 3.0653    ai1: 3.2969\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# num_iterations defined above\n",
    "\n",
    "# To safe some results\n",
    "res = [[],[]]\n",
    "loss = [[],[]]\n",
    "\n",
    "# Training Loop\n",
    "for i in range(num_iterations):\n",
    "    \n",
    "    # reset game\n",
    "    arena.reset()\n",
    "    \n",
    "    # play one game\n",
    "    arena.play()\n",
    "    \n",
    "    # save final score\n",
    "    res[0].append(ai0.score)\n",
    "    res[1].append(ai1.score)\n",
    "    \n",
    "    # save loss\n",
    "    loss[0].append(ai0.loss)\n",
    "    loss[1].append(ai1.loss)\n",
    "    \n",
    "    # print development\n",
    "    if (i+1) % 1000 == 0:\n",
    "        print(f'Game {i+1} / {int(num_iterations)}')\n",
    "        print(f'Average Score:  ai0: {sum(res[0])/len(res[0]):.3f}    ai1: {sum(res[1])/len(res[1]):.3f}')\n",
    "        print(f'Epsilon:        ai0: {ai0.epsilon() :.3f}     ai1: {ai1.epsilon() :.3f}')\n",
    "        print(f'Av. Last Loss:  ai0: {sum(loss[0])/len(loss[0]) :.4f}    ai1: {sum(loss[1])/len(loss[1]) :.4f}')\n",
    "        print('-------------------------------------------')\n",
    "        res = [[],[]]\n",
    "        loss = [[],[]]\n",
    "    \n",
    "    # The one that lost trains\n",
    "    if ai0.score > ai1.score:\n",
    "        ai1.update_step()\n",
    "    else:\n",
    "        ai0.update_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Loss has nothing to do with performance\n",
    "since the target_net changes regularly.\n",
    "\n",
    "So far, we do not have a good metric to rate\n",
    "the performance of the agents. \n",
    "\n",
    "We will figure out performance by testing \n",
    "the AI against random, greedy and human players. \n",
    "\n",
    "Before doing so, we investigate which move is the \n",
    "optimal initial move. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What (score(ai1) - score(ai0) = ?) does ai0 predict from the initial board?\n",
      "tensor([[-0.5466, -0.5519, -0.5708, -0.5928, -0.6589, -0.8565, -0.1591, -0.1143,\n",
      "          0.1243, -0.0187,  0.1029,  0.2972]], grad_fn=<AddmmBackward0>)\n",
      "How about ai1?\n",
      "tensor([[-0.4516, -0.4513, -0.5255, -0.6923, -0.9040, -0.8740, -0.3449, -0.2172,\n",
      "          0.0736,  0.0119,  0.0199,  0.2223]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('What (score(ai1) - score(ai0) = ?) does ai0 predict from the initial board?')\n",
    "\n",
    "print(ai0.target_net(torch.tensor([[4]*12], dtype=torch.float32)))\n",
    "\n",
    "print('How about ai1?')\n",
    "\n",
    "print(ai1.target_net(torch.tensor([[4]*12], dtype=torch.float32)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can learn:\n",
    "\n",
    "The best first actions in a game are:\n",
    "\n",
    "11 > 10 > 7 > 9, 8 > 6 > 3 > 4 > 0, 1 > 5 > 2\n",
    "according to ai0. \n",
    "\n",
    "ai1 seems to have a different opinion? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test\n",
    "Test performance against various players:\n",
    "- ai0 vs ai1\n",
    "- vs random\n",
    "- vs greedy\n",
    "- vs human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ai0 vs ai1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: Top AI: 19.736 - Bottom AI: 28.264\n"
     ]
    }
   ],
   "source": [
    "# ai0 vs ai1\n",
    "\n",
    "arena.test(ai0, ai1, num_games=500, disp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VS Random Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: Top AI: 27.81 - Bottom Random: 20.19\n"
     ]
    }
   ],
   "source": [
    "# ai0 vs random1\n",
    "\n",
    "arena.test(ai0, random1, num_games=500, disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: Top Random: 20.86 - Bottom AI: 27.14\n"
     ]
    }
   ],
   "source": [
    "# random0 vs ai1\n",
    "\n",
    "arena.test(random0, ai1, num_games=500, disp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI is better than random players."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VS Greedy Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: Top AI: 18.132 - Bottom Greedy: 29.868\n"
     ]
    }
   ],
   "source": [
    "# ai0 vs greedy1\n",
    "\n",
    "arena.test(ai0, greedy1, num_games=500, disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: Top Greedy: 29.972 - Bottom AI: 18.028\n"
     ]
    }
   ],
   "source": [
    "# greedy0 vs ai1\n",
    "\n",
    "arena.test(greedy0, ai1, num_games=500, disp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI is worse than a greedy player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VS Human\n",
    "\n",
    "Play a round against ai0 (AI on top position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game initialized!\n",
      "Top Player:    AI. Score: 1\n",
      "Bottom Player: Human. Score: 11\n",
      "[7, 0, 0, 6, 10, 0]\n",
      "[1, 0, 1, 0, 9, 2]End = False\n",
      "Next Player: Human\n",
      "[tensor([-1.2467,  0.0699, -0.0493, -0.2444, -0.3837, -1.2272,  0.1459,  0.1590,\n",
      "         0.6562, -0.1922,  0.4287,  0.0182], grad_fn=<UnbindBackward0>)]\n",
      "AI chooses 8\n",
      "Reward: 1\n",
      "Top Player:    AI. Score: 1\n",
      "Bottom Player: Human. Score: 0\n",
      "[5, 5, 5, 0, 4, 4]\n",
      "[4, 4, 4, 4, 4, 4]End = False\n",
      "Next Player: AI\n",
      "[tensor([-2.3094, -1.9140, -1.3966, -2.2820, -0.5283, -1.2177, -2.0655, -2.3037,\n",
      "         0.3879,  0.3351, -0.3050, -1.2057], grad_fn=<UnbindBackward0>)]\n",
      "AI chooses 9\n",
      "Reward: 1\n",
      "Top Player:    AI. Score: 2\n",
      "Bottom Player: Human. Score: 0\n",
      "[6, 6, 0, 0, 4, 4]\n",
      "[5, 5, 4, 4, 4, 4]End = False\n",
      "Next Player: Human\n",
      "It is Humans turn. Whats your next move? (input 0-11, end: 12)12\n",
      "Human chooses 12\n",
      "Reward: 0\n",
      "Game Over\n",
      "Average Score: Top AI: 22.0 - Bottom Human: 0.0\n"
     ]
    }
   ],
   "source": [
    "arena.test(ai0, human, num_games=1, disp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the AI is not very good atm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run ./Classes.ipynb\n",
    "#arena = Arena(game, ai0, ai1, disp=False) # disp=False to avoid output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
